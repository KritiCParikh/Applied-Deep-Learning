{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E_CslXXX0oxD","executionInfo":{"status":"ok","timestamp":1712890671142,"user_tz":300,"elapsed":267266,"user":{"displayName":"N. F.","userId":"01656730241496327416"}},"outputId":"671a0551-f366-4845-cf7b-a622fbe48e5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Batch [10/32], Loss: 0.6545\n","Epoch [1/10], Batch [20/32], Loss: 1.1160\n","Epoch [1/10], Batch [30/32], Loss: 0.6245\n","Epoch [1/10], Average Loss: 1.1188\n","Epoch [2/10], Batch [10/32], Loss: 0.7041\n","Epoch [2/10], Batch [20/32], Loss: 0.7914\n","Epoch [2/10], Batch [30/32], Loss: 0.7351\n","Epoch [2/10], Average Loss: 0.7848\n","Epoch [3/10], Batch [10/32], Loss: 0.7019\n","Epoch [3/10], Batch [20/32], Loss: 0.6059\n","Epoch [3/10], Batch [30/32], Loss: 0.7423\n","Epoch [3/10], Average Loss: 0.7463\n","Epoch [4/10], Batch [10/32], Loss: 0.7776\n","Epoch [4/10], Batch [20/32], Loss: 0.7830\n","Epoch [4/10], Batch [30/32], Loss: 0.6873\n","Epoch [4/10], Average Loss: 0.7228\n","Epoch [5/10], Batch [10/32], Loss: 0.7369\n","Epoch [5/10], Batch [20/32], Loss: 0.6925\n","Epoch [5/10], Batch [30/32], Loss: 0.7179\n","Epoch [5/10], Average Loss: 0.7131\n","Epoch [6/10], Batch [10/32], Loss: 0.7483\n","Epoch [6/10], Batch [20/32], Loss: 0.7060\n","Epoch [6/10], Batch [30/32], Loss: 0.6869\n","Epoch [6/10], Average Loss: 0.7188\n","Epoch [7/10], Batch [10/32], Loss: 0.7529\n","Epoch [7/10], Batch [20/32], Loss: 0.7376\n","Epoch [7/10], Batch [30/32], Loss: 0.7207\n","Epoch [7/10], Average Loss: 0.7027\n","Epoch [8/10], Batch [10/32], Loss: 0.6874\n","Epoch [8/10], Batch [20/32], Loss: 0.7057\n","Epoch [8/10], Batch [30/32], Loss: 0.6671\n","Epoch [8/10], Average Loss: 0.6996\n","Epoch [9/10], Batch [10/32], Loss: 0.6970\n","Epoch [9/10], Batch [20/32], Loss: 0.7019\n","Epoch [9/10], Batch [30/32], Loss: 0.7659\n","Epoch [9/10], Average Loss: 0.7189\n","Epoch [10/10], Batch [10/32], Loss: 0.7399\n","Epoch [10/10], Batch [20/32], Loss: 0.7024\n","Epoch [10/10], Batch [30/32], Loss: 0.7105\n","Epoch [10/10], Average Loss: 0.7149\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Define Ring Attention and Blockwise Transformer classes\n","\n","class RingAttention(nn.Module):\n","    def __init__(self, input_size, num_heads=8, block_size=16):\n","        super(RingAttention, self).__init__()\n","        self.input_size = input_size\n","        self.num_heads = num_heads\n","        self.block_size = block_size\n","\n","        self.query_projection = nn.Linear(input_size, input_size)\n","        self.key_projection = nn.Linear(input_size, input_size)\n","        self.value_projection = nn.Linear(input_size, input_size)\n","        self.output_projection = nn.Linear(input_size, input_size)\n","\n","    def forward(self, x):\n","        batch_size, seq_len, input_size = x.size()\n","        assert input_size == self.input_size\n","\n","        # Reshape input into blocks\n","        x = x.view(batch_size, -1, self.block_size, input_size)\n","\n","        # Apply projections\n","        queries = self.query_projection(x)  # [batch_size, num_blocks, block_size, input_size]\n","        keys = self.key_projection(x)  # [batch_size, num_blocks, block_size, input_size]\n","        values = self.value_projection(x)  # [batch_size, num_blocks, block_size, input_size]\n","\n","        # Compute attention scores\n","        attention_scores = torch.einsum('bijk,bilk->bijl', queries, keys) / (input_size ** 0.5)  # [batch_size, num_blocks, block_size, block_size]\n","        attention_weights = F.softmax(attention_scores, dim=-1)  # [batch_size, num_blocks, block_size, block_size]\n","\n","        # Apply attention to values\n","        attended_values = torch.einsum('bijl,bilk->bijk', attention_weights, values)  # [batch_size, num_blocks, block_size, input_size]\n","\n","        # Reshape back to original shape\n","        attended_values = attended_values.view(batch_size, seq_len, input_size)\n","\n","        # Apply output projection\n","        outputs = self.output_projection(attended_values)\n","\n","        return outputs\n","\n","class BlockwiseTransformer(nn.Module):\n","    def __init__(self, input_size, num_layers=4, num_heads=8, block_size=16):\n","        super(BlockwiseTransformer, self).__init__()\n","        self.input_size = input_size\n","        self.num_layers = num_layers\n","        self.num_heads = num_heads\n","        self.block_size = block_size\n","\n","        # Define Ring Attention layers\n","        RA_Layers = []\n","        for _ in range(num_layers):\n","          RA_Layers.append(RingAttention(input_size, num_heads, block_size))\n","        self.attention_layers = nn.ModuleList(RA_Layers)\n","\n","        # self.attention_layers = nn.ModuleList([RingAttention(input_size, num_heads, block_size) for _ in range(num_layers)])\n","\n","        # Feedforward layer\n","        self.feedforward = nn.Sequential(\n","            nn.Linear(input_size, 4 * input_size),\n","            nn.ReLU(),\n","            nn.Linear(4 * input_size, input_size)\n","        )\n","\n","    def forward(self, x):\n","        for layer in self.attention_layers:\n","            x = x + layer(x)  # Residual connection\n","            x = F.layer_norm(x, normalized_shape=x.size()[1:])  # Layer normalization\n","            x = self.feedforward(x)  # Feedforward layer\n","        return x\n","\n","# Define SyntheticDataset class\n","class SyntheticDataset(Dataset):\n","    def __init__(self, num_samples, seq_len, input_size):\n","        self.num_samples = num_samples\n","        self.seq_len = seq_len\n","        self.input_size = input_size\n","\n","    def __len__(self):\n","        return self.num_samples\n","\n","    def __getitem__(self, idx):\n","        # Generate random sequence tensor\n","        sequence = torch.randn(self.seq_len, self.input_size)\n","\n","        # Determine label based on some criteria (e.g., sum of the sequence)\n","        label = torch.tensor(1 if sequence.sum() > 0 else 0, dtype=torch.long)\n","\n","        return sequence, label\n","\n","# Instantiate the dataset and dataloader\n","num_samples = 1000  # Number of samples in the dataset\n","seq_len = 1024      # Length of each sequence\n","input_size = 512    # Dimensionality of each element in the sequence\n","batch_size = 32     # Batch size for training\n","dataset = SyntheticDataset(num_samples, seq_len, input_size)\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","# Instantiate the model\n","model = BlockwiseTransformer(input_size=input_size, num_layers=4, num_heads=8, block_size=16)\n","\n","# Define device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Define loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training loop\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    total_loss = 0.0\n","    for batch_idx, (inputs, targets) in enumerate(dataloader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","\n","        # Forward pass\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","\n","        # Compute loss\n","        loss = criterion(outputs.mean(dim=1), targets.squeeze())\n","\n","        # Backward pass and optimization\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","        if (batch_idx + 1) % 10 == 0:\n","            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {total_loss / len(dataloader):.4f}\")\n"]}]}